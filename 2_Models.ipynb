{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c2f7d94-e8e6-4f25-8c07-a672481a5003",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82e59bc-84b1-4f97-a5e0-64e906529847",
   "metadata": {},
   "source": [
    "- In this notebook, we will train various models and measure their performance by $MAE$, $MSE$, and $R^2$.\n",
    "- As the purpose of this project is to predict `popularity`, we decided that regression model is the the most appropriate. \n",
    "- Our selected models are the following:\n",
    "    1. Decision Tree\n",
    "    2. AdaBoost\n",
    "    3. Random Forest\n",
    "    4. Gradient Boosting (scikit-learn)\n",
    "    5. Histogram-based Gradient Boosting (scikit-learn)\n",
    "    6. XGBoost\n",
    "    7. LightGBM \n",
    "    8. CatBoost\n",
    "    9. K-Nearest Neighbors (KNN)\n",
    "    10. Multilayer Perceptron (MLP)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded00de2-3bb7-4db8-bbdd-c0f2287df742",
   "metadata": {},
   "source": [
    "## Preparing Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de9bb24-f595-478d-a298-59d53605c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e60bb9f7-740a-40ca-8ff3-1b10db76e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from utils.lds import LDS\n",
    "\n",
    "def split_data(df):\n",
    "    # Define the features and target variable\n",
    "    # X = df.drop(['popularity', 'weight'], axis=1)\n",
    "    df = LDS(df)\n",
    "    X = df.drop(['popularity', 'weight'], axis=1)\n",
    "    y = df['popularity']\n",
    "    # Splitting the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test, weights_train, weights_test = train_test_split(\n",
    "        X, y, df['weight'], test_size=0.2, random_state=42\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test, weights_train, weights_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "97cf8282-d683-493e-9e94-7b4f1eda066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def model_performance(model_name, y_test, y_pred, weights_test=None):\n",
    "    mae = mean_absolute_error(y_test, y_pred, sample_weight=weights_test)\n",
    "    mse = mean_squared_error(y_test, y_pred, sample_weight=weights_test)\n",
    "    r2 = r2_score(y_test, y_pred, sample_weight=weights_test)\n",
    "    print(f\"Model Performance ({model_name}):\\nMAE = {mae}\\nMSE = {mse}\\nR^2 = {r2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535ca10-3b0c-44cf-b053-a86f88ae1ece",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f01df0-559d-46c2-9517-4e8e6581cc60",
   "metadata": {},
   "source": [
    "## Models Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c309d3b8-2064-46b1-96e9-cbbb4825e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "750f3eb8-d4ee-45f1-b3f3-d285f8aac964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models:\n",
    "    def __init__(self, df, lds=False):\n",
    "        self.df = df\n",
    "        self.LDS = LDS\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test, self.w_train, self.w_test  = split_data(self.df)\n",
    "        \n",
    "        scaler = StandardScaler()  \n",
    "        scaler.fit(self.X_train)\n",
    "        self.X_train_standardized = scaler.transform(self.X_train)  \n",
    "        self.X_test_standardized = scaler.transform(self.X_test)  \n",
    "\n",
    "        normalizer = Normalizer()\n",
    "        normalizer.fit(self.X_train)\n",
    "        self.X_train_normalized = normalizer.transform(self.X_train)\n",
    "        self.X_test_normalized = normalizer.transform(self.X_test)\n",
    "\n",
    "        self.DecisionTree()\n",
    "        self.AdaBoost()\n",
    "        self.RandomForest()\n",
    "        self.GB()\n",
    "        self.HistGB()\n",
    "        self.XGBoost()\n",
    "        self.LGBM()\n",
    "        self.CatBoost()\n",
    "        self.KNN()\n",
    "        self.MLP()\n",
    "\n",
    "    def run_model(self, regr, model_name):\n",
    "        regr.fit(self.X_train, self.y_train)\n",
    "        y_pred = regr.predict(self.X_test)\n",
    "        model_performance(model_name=f\"{model_name}\", y_test=self.y_test, y_pred=y_pred)\n",
    "        \n",
    "        regr.fit(self.X_train, self.y_train, sample_weight=self.w_train)\n",
    "        y_pred = regr.predict(self.X_test)\n",
    "        model_performance(model_name=f\"{model_name} (with LDS)\", y_test=self.y_test, y_pred=y_pred, weights_test=self.w_test)\n",
    "    \n",
    "    def DecisionTree(self):\n",
    "        regr = DecisionTreeRegressor()\n",
    "        self.run_model(regr, \"Decision Tree\")\n",
    "    \n",
    "    def AdaBoost(self):\n",
    "        regr = AdaBoostRegressor(DecisionTreeRegressor(), n_estimators=50)\n",
    "        self.run_model(regr, \"AdaBoost\")\n",
    "\n",
    "    def RandomForest(self):\n",
    "        regr = RandomForestRegressor(n_estimators=100)\n",
    "        self.run_model(regr, \"Random Forest\")\n",
    "\n",
    "    def GB(self):\n",
    "        regr = GradientBoostingRegressor(n_estimators=100)\n",
    "        self.run_model(regr, \"Gradient Boosting\")\n",
    "\n",
    "    def HistGB(self):\n",
    "        regr = HistGradientBoostingRegressor(max_iter=100)\n",
    "        self.run_model(regr, \"Hist Gradient Boosting\")\n",
    "\n",
    "    def XGBoost(self):\n",
    "        regr = XGBRegressor(objective='reg:squarederror', n_estimators=100)\n",
    "        self.run_model(regr, \"XGBoost\")\n",
    "\n",
    "    def LGBM(self):\n",
    "        regr = lgb.LGBMRegressor()\n",
    "        regr.fit(self.X_train, self.y_train, eval_set=[(self.X_test, self.y_test)], eval_metric='mse')\n",
    "        y_pred = regr.predict(self.X_test, num_iteration=regr.best_iteration_)\n",
    "        model_performance(model_name=f\"LightGBM\", y_test=self.y_test, y_pred=y_pred)\n",
    "\n",
    "    def CatBoost(self):\n",
    "        regr = CatBoostRegressor(verbose=0)\n",
    "        regr.fit(self.X_train, self.y_train, eval_set=(self.X_test, self.y_test), use_best_model=True)\n",
    "        y_pred = regr.predict(self.X_test)\n",
    "        model_performance(model_name=f\"CatBoost\", y_test=self.y_test, y_pred=y_pred)\n",
    "\n",
    "    def KNN(self):\n",
    "        regr = KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "        regr.fit(self.X_train_normalized, self.y_train)\n",
    "        y_pred = regr.predict(self.X_test_normalized)\n",
    "        model_performance(model_name=f\"K-Nearest Neighbors\", y_test=self.y_test, y_pred=y_pred)\n",
    "\n",
    "    def MLP(self):\n",
    "        params = { 'hidden_layer_sizes' : [10,10],\n",
    "            'activation' : 'relu', 'solver' : 'adam',\n",
    "            'alpha' : 0.0, 'batch_size' : 10,\n",
    "            'random_state' : 0, 'tol' : 0.0001,\n",
    "            'nesterovs_momentum' : False,\n",
    "            'learning_rate' : 'constant',\n",
    "            'learning_rate_init' : 0.01,\n",
    "            'max_iter' : 1000, 'shuffle' : True,\n",
    "            'n_iter_no_change' : 50, 'verbose' : False }\n",
    "        regr = MLPRegressor(**params)\n",
    "        regr.fit(self.X_train_standardized, self.y_train)\n",
    "        y_pred = regr.predict(self.X_test_standardized)\n",
    "        model_performance(model_name=f\"Multilayer Perceptron\", y_test=self.y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af2c372-a888-4e5f-ade4-a3383104e5e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68301058-33d8-4ee3-8011-c80e84093827",
   "metadata": {},
   "source": [
    "## Models Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b97df8ad-b768-40ed-bef5-b3d43c0ac7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv(\"./data/cleandata.csv\")\n",
    "smogn_02_df = pd.read_csv(\"data/data_smogn_02.csv\")\n",
    "smogn_03_df = pd.read_csv(\"data/data_smogn_03.csv\")\n",
    "smogn_04_df = pd.read_csv(\"data/data_smogn_04.csv\")\n",
    "smogn_05_df = pd.read_csv(\"data/data_smogn_05.csv\")\n",
    "smogn_06_df = pd.read_csv(\"data/data_smogn_06.csv\")\n",
    "smogn_07_df = pd.read_csv(\"data/data_smogn_07.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa505ad-ea50-4d0a-965c-3f076911d2ac",
   "metadata": {},
   "source": [
    "Every dataset contains `weight` column for LDS, so we will run every model twice (if applicable) for each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dea30e-58c6-403d-8cf5-666b60d1d7c2",
   "metadata": {},
   "source": [
    "### Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4b67f557-b555-4aa5-addb-f3f0db16798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on Original Data\n",
      "\n",
      "Model Performance (Decision Tree):\n",
      "MAE = 18.57303879374284\n",
      "MSE = 626.0107864451937\n",
      "R^2 = -0.49874256892663915\n",
      "\n",
      "Model Performance (Decision Tree (with LDS)):\n",
      "MAE = 20.66388842328596\n",
      "MSE = 793.1598373315657\n",
      "R^2 = -0.298831402242413\n",
      "\n",
      "Model Performance (AdaBoost):\n",
      "MAE = 13.967791767936056\n",
      "MSE = 358.3783201872458\n",
      "R^2 = 0.1420006557793232\n",
      "\n",
      "Model Performance (AdaBoost (with LDS)):\n",
      "MAE = 16.903356135701582\n",
      "MSE = 527.0719225538452\n",
      "R^2 = 0.13689835007740014\n",
      "\n",
      "Model Performance (Random Forest):\n",
      "MAE = 13.570182674839362\n",
      "MSE = 316.3434660426139\n",
      "R^2 = 0.24263698130164324\n",
      "\n",
      "Model Performance (Random Forest (with LDS)):\n",
      "MAE = 16.976347682630145\n",
      "MSE = 489.81150643928197\n",
      "R^2 = 0.1979137926558212\n",
      "\n",
      "Model Performance (Gradient Boosting):\n",
      "MAE = 15.78093795728254\n",
      "MSE = 379.6811001725244\n",
      "R^2 = 0.09099932498482466\n",
      "\n",
      "Model Performance (Gradient Boosting (with LDS)):\n",
      "MAE = 19.19209511925938\n",
      "MSE = 542.3431466970196\n",
      "R^2 = 0.11189110117966516\n",
      "\n",
      "Model Performance (Hist Gradient Boosting):\n",
      "MAE = 15.271570941264088\n",
      "MSE = 361.8995488684064\n",
      "R^2 = 0.13357042512890793\n",
      "\n",
      "Model Performance (Hist Gradient Boosting (with LDS)):\n",
      "MAE = 18.636458275399267\n",
      "MSE = 523.1217537047938\n",
      "R^2 = 0.14336691177685346\n",
      "\n",
      "Model Performance (XGBoost):\n",
      "MAE = 14.865753694640167\n",
      "MSE = 352.4197619109543\n",
      "R^2 = 0.15626613671267764\n",
      "\n",
      "Model Performance (XGBoost (with LDS)):\n",
      "MAE = 18.26429647268663\n",
      "MSE = 518.8633928376929\n",
      "R^2 = 0.1503401504053733\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2548\n",
      "[LightGBM] [Info] Number of data points in the train set: 71792, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 33.234441\n",
      "Model Performance (LightGBM):\n",
      "MAE = 15.226399350371095\n",
      "MSE = 360.4494084737903\n",
      "R^2 = 0.13704222974855806\n",
      "\n",
      "Model Performance (CatBoost):\n",
      "MAE = 14.82264940159378\n",
      "MSE = 348.4035169118616\n",
      "R^2 = 0.16588149395206286\n",
      "\n",
      "Model Performance (K-Nearest Neighbors):\n",
      "MAE = 16.006777882398886\n",
      "MSE = 436.4518512057881\n",
      "R^2 = -0.04491645008774636\n",
      "\n",
      "Model Performance (Multilayer Perceptron):\n",
      "MAE = 15.785708754750162\n",
      "MSE = 384.4531143840716\n",
      "R^2 = 0.07957456842594568\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Models at 0x2b7e421e0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model on Original Data\\n')\n",
    "Models(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72244950-eae3-421b-9c8f-29e737379173",
   "metadata": {},
   "source": [
    "### SMOGN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a104a39b-c56d-4d89-9233-a2e76292574d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on SMOGN (rel_thes = 0.2) Data\n",
      "Model Performance (Decision Tree):\n",
      "MAE = 16.301484614755623\n",
      "MSE = 545.7004294895336\n",
      "R^2 = -0.2765477600036472\n",
      "\n",
      "Model Performance (Decision Tree (with LDS)):\n",
      "MAE = 19.382233282772596\n",
      "MSE = 731.6062792768417\n",
      "R^2 = 0.0002390503146730838\n",
      "\n",
      "Model Performance (AdaBoost):\n",
      "MAE = 12.068041889513362\n",
      "MSE = 307.67921831284394\n",
      "R^2 = 0.2802512226271443\n",
      "\n",
      "Model Performance (AdaBoost (with LDS)):\n",
      "MAE = 15.720310727524597\n",
      "MSE = 487.9394701764362\n",
      "R^2 = 0.3332167288466429\n",
      "\n",
      "Model Performance (Random Forest):\n",
      "MAE = 12.052907398880418\n",
      "MSE = 272.3400660189963\n",
      "R^2 = 0.3629195022606023\n",
      "\n",
      "Model Performance (Random Forest (with LDS)):\n",
      "MAE = 16.044316611782634\n",
      "MSE = 451.22416867541546\n",
      "R^2 = 0.38338924066943136\n",
      "\n",
      "Model Performance (Gradient Boosting):\n",
      "MAE = 13.084112321699024\n",
      "MSE = 299.8431935870048\n",
      "R^2 = 0.29858190237474924\n",
      "\n",
      "Model Performance (Gradient Boosting (with LDS)):\n",
      "MAE = 17.219800362443856\n",
      "MSE = 446.25719125497096\n",
      "R^2 = 0.3901767576763079\n",
      "\n",
      "Model Performance (Hist Gradient Boosting):\n",
      "MAE = 12.69028118615039\n",
      "MSE = 289.0049045168085\n",
      "R^2 = 0.32393572818678573\n",
      "\n",
      "Model Performance (Hist Gradient Boosting (with LDS)):\n",
      "MAE = 16.6621392224442\n",
      "MSE = 429.97520142671056\n",
      "R^2 = 0.41242656344555106\n",
      "\n",
      "Model Performance (XGBoost):\n",
      "MAE = 12.695710983643757\n",
      "MSE = 291.12470371157747\n",
      "R^2 = 0.3189769178807883\n",
      "\n",
      "Model Performance (XGBoost (with LDS)):\n",
      "MAE = 16.458921643741803\n",
      "MSE = 437.70435130818237\n",
      "R^2 = 0.4018644586022212\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 55834, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 48.452341\n",
      "Model Performance (LightGBM):\n",
      "MAE = 12.696475203166072\n",
      "MSE = 288.5864073500429\n",
      "R^2 = 0.32491471151157836\n",
      "\n",
      "Model Performance (CatBoost):\n",
      "MAE = 12.510906967134686\n",
      "MSE = 283.7027220804065\n",
      "R^2 = 0.33633903363892004\n",
      "\n",
      "Model Performance (K-Nearest Neighbors):\n",
      "MAE = 13.992281291570324\n",
      "MSE = 373.425595011175\n",
      "R^2 = 0.12645183862973752\n",
      "\n",
      "Model Performance (Multilayer Perceptron):\n",
      "MAE = 13.115367670396612\n",
      "MSE = 302.22078912553775\n",
      "R^2 = 0.2930200334538322\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Models at 0x2b7e42720>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model on SMOGN (rel_thes = 0.2) Data')\n",
    "Models(smogn_02_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d1cdeccb-0061-4169-9b11-e62b5908968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on SMOGN (rel_thes = 0.3) Data\n",
      "Model Performance (Decision Tree):\n",
      "MAE = 15.625271878453967\n",
      "MSE = 525.7334359931481\n",
      "R^2 = -0.06940478321302912\n",
      "\n",
      "Model Performance (Decision Tree (with LDS)):\n",
      "MAE = 18.261542034966045\n",
      "MSE = 670.1177808012253\n",
      "R^2 = 0.17270353980366648\n",
      "\n",
      "Model Performance (AdaBoost):\n",
      "MAE = 11.893243063444467\n",
      "MSE = 309.29104644490485\n",
      "R^2 = 0.3708649634423191\n",
      "\n",
      "Model Performance (AdaBoost (with LDS)):\n",
      "MAE = 14.928763554929198\n",
      "MSE = 444.2266553552305\n",
      "R^2 = 0.4515782896242069\n",
      "\n",
      "Model Performance (Random Forest):\n",
      "MAE = 11.816574127935272\n",
      "MSE = 271.32354551135813\n",
      "R^2 = 0.4480954082366069\n",
      "\n",
      "Model Performance (Random Forest (with LDS)):\n",
      "MAE = 15.081717387550938\n",
      "MSE = 403.32886560534797\n",
      "R^2 = 0.5020688118268523\n",
      "\n",
      "Model Performance (Gradient Boosting):\n",
      "MAE = 12.745526028822013\n",
      "MSE = 295.11150177649483\n",
      "R^2 = 0.3997078557790701\n",
      "\n",
      "Model Performance (Gradient Boosting (with LDS)):\n",
      "MAE = 16.01248532086322\n",
      "MSE = 403.8682982007494\n",
      "R^2 = 0.5014028532603498\n",
      "\n",
      "Model Performance (Hist Gradient Boosting):\n",
      "MAE = 12.418368882855493\n",
      "MSE = 284.6907774970779\n",
      "R^2 = 0.4209048571984316\n",
      "\n",
      "Model Performance (Hist Gradient Boosting (with LDS)):\n",
      "MAE = 15.627208241634749\n",
      "MSE = 390.89628302075494\n",
      "R^2 = 0.5174175040388909\n",
      "\n",
      "Model Performance (XGBoost):\n",
      "MAE = 12.34461013818747\n",
      "MSE = 283.8316989781987\n",
      "R^2 = 0.42265232580961\n",
      "\n",
      "Model Performance (XGBoost (with LDS)):\n",
      "MAE = 15.45986195503266\n",
      "MSE = 392.75961332631545\n",
      "R^2 = 0.515117122508761\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 60429, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 49.643797\n",
      "Model Performance (LightGBM):\n",
      "MAE = 12.38876455799143\n",
      "MSE = 282.45454094059437\n",
      "R^2 = 0.42545363021946214\n",
      "\n",
      "Model Performance (CatBoost):\n",
      "MAE = 12.258447492711879\n",
      "MSE = 278.04095084968014\n",
      "R^2 = 0.43443140114142953\n",
      "\n",
      "Model Performance (K-Nearest Neighbors):\n",
      "MAE = 13.485009782862273\n",
      "MSE = 360.14795426424945\n",
      "R^2 = 0.2674159210988528\n",
      "\n",
      "Model Performance (Multilayer Perceptron):\n",
      "MAE = 12.652554008494128\n",
      "MSE = 300.24216636008146\n",
      "R^2 = 0.38927146944502533\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Models at 0x2b7f38560>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model on SMOGN (rel_thes = 0.3) Data')\n",
    "Models(smogn_03_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "42761cf6-771b-49d0-bc01-717efb750158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on SMOGN (rel_thes = 0.4) Data\n",
      "Model Performance (Decision Tree):\n",
      "MAE = 9.374191788498614\n",
      "MSE = 321.7865053062617\n",
      "R^2 = 0.47192265249052523\n",
      "\n",
      "Model Performance (Decision Tree (with LDS)):\n",
      "MAE = 11.285137683541695\n",
      "MSE = 406.40276134678265\n",
      "R^2 = 0.5048283330850346\n",
      "\n",
      "Model Performance (AdaBoost):\n",
      "MAE = 7.6036393955674235\n",
      "MSE = 188.90721015418782\n",
      "R^2 = 0.6899881852761547\n",
      "\n",
      "Model Performance (AdaBoost (with LDS)):\n",
      "MAE = 9.325801723981666\n",
      "MSE = 254.5279884638352\n",
      "R^2 = 0.6898764961476114\n",
      "\n",
      "Model Performance (Random Forest):\n",
      "MAE = 7.812471176387853\n",
      "MSE = 172.5189944364946\n",
      "R^2 = 0.7168825557482036\n",
      "\n",
      "Model Performance (Random Forest (with LDS)):\n",
      "MAE = 9.660554970766746\n",
      "MSE = 234.18818829317564\n",
      "R^2 = 0.7146590363100996\n",
      "\n",
      "Model Performance (Gradient Boosting):\n",
      "MAE = 12.875783040384396\n",
      "MSE = 313.76331965767014\n",
      "R^2 = 0.4850893407326311\n",
      "\n",
      "Model Performance (Gradient Boosting (with LDS)):\n",
      "MAE = 14.743113445233416\n",
      "MSE = 378.39237959788426\n",
      "R^2 = 0.5389569088249306\n",
      "\n",
      "Model Performance (Hist Gradient Boosting):\n",
      "MAE = 12.26834053963555\n",
      "MSE = 288.7899536697897\n",
      "R^2 = 0.5260726282595943\n",
      "\n",
      "Model Performance (Hist Gradient Boosting (with LDS)):\n",
      "MAE = 13.942984033839018\n",
      "MSE = 346.6691809080943\n",
      "R^2 = 0.5776092770397567\n",
      "\n",
      "Model Performance (XGBoost):\n",
      "MAE = 11.561932497847751\n",
      "MSE = 263.7888683538074\n",
      "R^2 = 0.5671014054171588\n",
      "\n",
      "Model Performance (XGBoost (with LDS)):\n",
      "MAE = 12.99637037175775\n",
      "MSE = 311.4794434927536\n",
      "R^2 = 0.620485365963241\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 82052, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 51.926620\n",
      "Model Performance (LightGBM):\n",
      "MAE = 12.267864441182786\n",
      "MSE = 287.8114223937175\n",
      "R^2 = 0.5276784762122034\n",
      "\n",
      "Model Performance (CatBoost):\n",
      "MAE = 11.603581281343933\n",
      "MSE = 265.0744893531541\n",
      "R^2 = 0.5649915987097851\n",
      "\n",
      "Model Performance (K-Nearest Neighbors):\n",
      "MAE = 9.634738772086214\n",
      "MSE = 255.1771767392456\n",
      "R^2 = 0.5812338789373244\n",
      "\n",
      "Model Performance (Multilayer Perceptron):\n",
      "MAE = 12.876667376203276\n",
      "MSE = 315.0664801620239\n",
      "R^2 = 0.4829507502971395\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Models at 0x2a0db8ad0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model on SMOGN (rel_thes = 0.4) Data')\n",
    "Models(smogn_04_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3473a0d3-7b60-48f5-a6a0-4284115922f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on SMOGN (rel_thes = 0.5) Data\n",
      "Model Performance (Decision Tree):\n",
      "MAE = 11.128184492331886\n",
      "MSE = 384.36702432711246\n",
      "R^2 = 0.6222586014442659\n",
      "\n",
      "Model Performance (Decision Tree (with LDS)):\n",
      "MAE = 11.788212620035374\n",
      "MSE = 412.8200054084128\n",
      "R^2 = 0.675259555731869\n",
      "\n",
      "Model Performance (AdaBoost):\n",
      "MAE = 8.661235243969656\n",
      "MSE = 219.80477067613853\n",
      "R^2 = 0.783984170781088\n",
      "\n",
      "Model Performance (AdaBoost (with LDS)):\n",
      "MAE = 9.585604554094648\n",
      "MSE = 255.34124576345192\n",
      "R^2 = 0.7991385385813194\n",
      "\n",
      "Model Performance (Random Forest):\n",
      "MAE = 9.431072990485024\n",
      "MSE = 201.25107895493323\n",
      "R^2 = 0.8022180384532935\n",
      "\n",
      "Model Performance (Random Forest (with LDS)):\n",
      "MAE = 10.165269504474209\n",
      "MSE = 229.1633075655677\n",
      "R^2 = 0.8197311338262963\n",
      "\n",
      "Model Performance (Gradient Boosting):\n",
      "MAE = 16.689873771002194\n",
      "MSE = 412.5791771822984\n",
      "R^2 = 0.5945327628543338\n",
      "\n",
      "Model Performance (Gradient Boosting (with LDS)):\n",
      "MAE = 17.721417236738205\n",
      "MSE = 441.271300847027\n",
      "R^2 = 0.6528786483153333\n",
      "\n",
      "Model Performance (Hist Gradient Boosting):\n",
      "MAE = 15.513123074368908\n",
      "MSE = 373.72949538563853\n",
      "R^2 = 0.6327127632354965\n",
      "\n",
      "Model Performance (Hist Gradient Boosting (with LDS)):\n",
      "MAE = 16.504829298655732\n",
      "MSE = 405.1332096149183\n",
      "R^2 = 0.6813062914720815\n",
      "\n",
      "Model Performance (XGBoost):\n",
      "MAE = 13.899570562442051\n",
      "MSE = 317.6957121661165\n",
      "R^2 = 0.6877806496567251\n",
      "\n",
      "Model Performance (XGBoost (with LDS)):\n",
      "MAE = 14.684786516068579\n",
      "MSE = 342.7305851594226\n",
      "R^2 = 0.73039464892493\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 85095, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 58.057007\n",
      "Model Performance (LightGBM):\n",
      "MAE = 15.412885510728662\n",
      "MSE = 367.20783755876425\n",
      "R^2 = 0.6391220023026045\n",
      "\n",
      "Model Performance (CatBoost):\n",
      "MAE = 14.164890704327016\n",
      "MSE = 323.979276523418\n",
      "R^2 = 0.6816053998615658\n",
      "\n",
      "Model Performance (K-Nearest Neighbors):\n",
      "MAE = 10.854762289483734\n",
      "MSE = 296.8491834214765\n",
      "R^2 = 0.7082678309824859\n",
      "\n",
      "Model Performance (Multilayer Perceptron):\n",
      "MAE = 16.528589683915886\n",
      "MSE = 430.74359847315327\n",
      "R^2 = 0.5766814554629804\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Models at 0x2b7e85850>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model on SMOGN (rel_thes = 0.5) Data')\n",
    "Models(smogn_05_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "07ea6053-d678-43d4-94e5-f3a628b20bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on SMOGN (rel_thes = 0.6) Data\n",
      "Model Performance (Decision Tree):\n",
      "MAE = 16.73812059954372\n",
      "MSE = 670.3386482017439\n",
      "R^2 = 0.06806625163430347\n",
      "\n",
      "Model Performance (Decision Tree (with LDS)):\n",
      "MAE = 19.05719752915164\n",
      "MSE = 805.2937856215826\n",
      "R^2 = 0.10778981124546472\n",
      "\n",
      "Model Performance (AdaBoost):\n",
      "MAE = 11.967897112142943\n",
      "MSE = 356.80555115261086\n",
      "R^2 = 0.5039535082523445\n",
      "\n",
      "Model Performance (AdaBoost (with LDS)):\n",
      "MAE = 14.28931164045594\n",
      "MSE = 468.5619491775642\n",
      "R^2 = 0.48086555169897083\n",
      "\n",
      "Model Performance (Random Forest):\n",
      "MAE = 12.79229353754437\n",
      "MSE = 334.3755939928361\n",
      "R^2 = 0.5351366037036751\n",
      "\n",
      "Model Performance (Random Forest (with LDS)):\n",
      "MAE = 15.21206105689856\n",
      "MSE = 450.3624080665331\n",
      "R^2 = 0.5010293928956162\n",
      "\n",
      "Model Performance (Gradient Boosting):\n",
      "MAE = 16.857621054595413\n",
      "MSE = 487.41775520131387\n",
      "R^2 = 0.32237077954060267\n",
      "\n",
      "Model Performance (Gradient Boosting (with LDS)):\n",
      "MAE = 20.39563370142627\n",
      "MSE = 631.39263726369\n",
      "R^2 = 0.3004603361785054\n",
      "\n",
      "Model Performance (Hist Gradient Boosting):\n",
      "MAE = 15.380302887279159\n",
      "MSE = 431.6263603116162\n",
      "R^2 = 0.3999343869882501\n",
      "\n",
      "Model Performance (Hist Gradient Boosting (with LDS)):\n",
      "MAE = 18.213871244329294\n",
      "MSE = 546.2994872156338\n",
      "R^2 = 0.39473770031772193\n",
      "\n",
      "Model Performance (XGBoost):\n",
      "MAE = 14.606124901455734\n",
      "MSE = 395.9847961357088\n",
      "R^2 = 0.44948482927465905\n",
      "\n",
      "Model Performance (XGBoost (with LDS)):\n",
      "MAE = 17.211269370917602\n",
      "MSE = 499.8822650278068\n",
      "R^2 = 0.4461647935215969\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 68620, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 54.705960\n",
      "Model Performance (LightGBM):\n",
      "MAE = 15.37709033355856\n",
      "MSE = 431.5334622790363\n",
      "R^2 = 0.4000635378464772\n",
      "\n",
      "Model Performance (CatBoost):\n",
      "MAE = 14.484735911957747\n",
      "MSE = 386.8187776426976\n",
      "R^2 = 0.46222782416939834\n",
      "\n",
      "Model Performance (K-Nearest Neighbors):\n",
      "MAE = 18.659069030163078\n",
      "MSE = 638.0478216705859\n",
      "R^2 = 0.11295835369008689\n",
      "\n",
      "Model Performance (Multilayer Perceptron):\n",
      "MAE = 16.6188726722409\n",
      "MSE = 511.1208484943576\n",
      "R^2 = 0.28941771523540993\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Models at 0x286aa0980>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model on SMOGN (rel_thes = 0.6) Data')\n",
    "Models(smogn_06_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3944faa3-0b23-4ad9-b465-389593cd164a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on SMOGN (rel_thes = 0.7) Data\n",
      "Model Performance (Decision Tree):\n",
      "MAE = 15.808059337419852\n",
      "MSE = 652.5741862358093\n",
      "R^2 = 0.20625547293268998\n",
      "\n",
      "Model Performance (Decision Tree (with LDS)):\n",
      "MAE = 17.678176973397264\n",
      "MSE = 744.8904588765482\n",
      "R^2 = 0.2363740774631844\n",
      "\n",
      "Model Performance (AdaBoost):\n",
      "MAE = 11.242900399827912\n",
      "MSE = 336.9000101979445\n",
      "R^2 = 0.5902189438322203\n",
      "\n",
      "Model Performance (AdaBoost (with LDS)):\n",
      "MAE = 13.418966578918473\n",
      "MSE = 435.4235669121206\n",
      "R^2 = 0.5536246719027385\n",
      "\n",
      "Model Performance (Random Forest):\n",
      "MAE = 12.204938833762483\n",
      "MSE = 317.61306779145764\n",
      "R^2 = 0.613678199962648\n",
      "\n",
      "Model Performance (Random Forest (with LDS)):\n",
      "MAE = 14.42348563283199\n",
      "MSE = 421.874916740186\n",
      "R^2 = 0.5675140973388975\n",
      "\n",
      "Model Performance (Gradient Boosting):\n",
      "MAE = 17.28554332334455\n",
      "MSE = 521.3228609030697\n",
      "R^2 = 0.3659001897335892\n",
      "\n",
      "Model Performance (Gradient Boosting (with LDS)):\n",
      "MAE = 20.394429108619878\n",
      "MSE = 644.4823053600308\n",
      "R^2 = 0.3393076940044806\n",
      "\n",
      "Model Performance (Hist Gradient Boosting):\n",
      "MAE = 15.74042622809681\n",
      "MSE = 457.66022487066033\n",
      "R^2 = 0.4433348630553796\n",
      "\n",
      "Model Performance (Hist Gradient Boosting (with LDS)):\n",
      "MAE = 18.253100329738007\n",
      "MSE = 556.9065364563222\n",
      "R^2 = 0.4290861661597384\n",
      "\n",
      "Model Performance (XGBoost):\n",
      "MAE = 14.726586947007922\n",
      "MSE = 408.0948753982241\n",
      "R^2 = 0.5036226061284843\n",
      "\n",
      "Model Performance (XGBoost (with LDS)):\n",
      "MAE = 17.231417401449058\n",
      "MSE = 505.04449847557055\n",
      "R^2 = 0.48225263664644713\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 69896, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 56.476880\n",
      "Model Performance (LightGBM):\n",
      "MAE = 15.681874595941924\n",
      "MSE = 452.74921027915985\n",
      "R^2 = 0.44930826966043735\n",
      "\n",
      "Model Performance (CatBoost):\n",
      "MAE = 14.698947693598987\n",
      "MSE = 403.321291700872\n",
      "R^2 = 0.5094288516315845\n",
      "\n",
      "Model Performance (K-Nearest Neighbors):\n",
      "MAE = 19.124867991111376\n",
      "MSE = 678.3725503171547\n",
      "R^2 = 0.17487618958258466\n",
      "\n",
      "Model Performance (Multilayer Perceptron):\n",
      "MAE = 16.91424398899482\n",
      "MSE = 536.7012694175329\n",
      "R^2 = 0.347194994445724\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Models at 0x2a0db6420>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model on SMOGN (rel_thes = 0.7) Data')\n",
    "Models(smogn_07_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
