{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c2f7d94-e8e6-4f25-8c07-a672481a5003",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82e59bc-84b1-4f97-a5e0-64e906529847",
   "metadata": {},
   "source": [
    "- In this notebook, we will train various models and measure their performance by $MAE$, $MSE$, and $R^2$.\n",
    "- As the purpose of this project is to predict `popularity`, we decided that regression model is the the most appropriate. \n",
    "- Our selected models are the following:\n",
    "    1. Decision Tree\n",
    "    2. AdaBoost\n",
    "    3. Random Forest\n",
    "    4. Gradient Boosting (scikit-learn)\n",
    "    5. Hist Gradient Boosting (scikit-learn)\n",
    "    6. XGBoost\n",
    "    7. LightGBM \n",
    "    8. CatBoost\n",
    "    9. K-Nearest Neighbors (KNN)\n",
    "    10. Multilayer Perceptron (MLP)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded00de2-3bb7-4db8-bbdd-c0f2287df742",
   "metadata": {},
   "source": [
    "## Preparing Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de9bb24-f595-478d-a298-59d53605c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e60bb9f7-740a-40ca-8ff3-1b10db76e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def split_data(df, LDS=False, S=False, N=False):\n",
    "    # Define the features and target variable\n",
    "    # X = df.drop(['popularity', 'weight'], axis=1)\n",
    "    X = df.drop(['popularity'], axis=1)\n",
    "    y = df['popularity']\n",
    "    # Splitting the dataset into training and testing sets\n",
    "    if LDS == False: \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        # Split data, including weights\n",
    "        X_train, X_test, y_train, y_test, weights_train, weights_test = train_test_split(\n",
    "            X, y, df['weight'], test_size=0.2, random_state=42\n",
    "        )\n",
    "        normalizer = Normalizer()\n",
    "        normalizer.fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "        return X_train, X_test, y_train, y_test, weights_train, weights_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "97cf8282-d683-493e-9e94-7b4f1eda066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def model_performace(model_name, y_test, y_pred, weights_test=None):\n",
    "    mae = mean_absolute_error(y_test, y_pred, sample_weight=weights_test)\n",
    "    mse = mean_squared_error(y_test, y_pred, sample_weight=weights_test)\n",
    "    r2 = r2_score(y_test, y_pred, sample_weight=weights_test)\n",
    "    print(f\"Model Performance ({model_name}):\\nMAE = {mae}\\nMSE = {mse}\\nR^2 = {r2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535ca10-3b0c-44cf-b053-a86f88ae1ece",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f01df0-559d-46c2-9517-4e8e6581cc60",
   "metadata": {},
   "source": [
    "## Models Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c309d3b8-2064-46b1-96e9-cbbb4825e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "750f3eb8-d4ee-45f1-b3f3-d285f8aac964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models:\n",
    "    def __init__(self, df, LDS=False):\n",
    "        self.df = df\n",
    "        self.LDS = LDS\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = split_data(df)\n",
    "        \n",
    "        scaler = StandardScaler()  \n",
    "        scaler.fit(self.X_train)\n",
    "        self.X_train_standardized = scaler.transform(self.X_train)  \n",
    "        self.X_test_standardized = scaler.transform(self.X_test)  \n",
    "\n",
    "        normalizer = Normalizer()\n",
    "        normalizer.fit(self.X_train)\n",
    "        self.X_train_normalized = normalizer.transform(self.X_train)\n",
    "        self.X_test_normalized = normalizer.transform(self.X_test)\n",
    "        \n",
    "        if self.LDS == True: \n",
    "            self.X_train_LDS, self.X_test_LDS, self.y_train_LDS, self.y_test_LDS, self.w_train, self.w_test = split_data(df, LDS=True)\n",
    "\n",
    "        self.DecisionTree()\n",
    "        self.AdaBoost()\n",
    "        self.RandomForest()\n",
    "        self.GB()\n",
    "        self.HistGB()\n",
    "        self.XGBoost()\n",
    "        self.LGBM()\n",
    "        self.CatBoost()\n",
    "        self.KNN()\n",
    "        self.MLP()\n",
    "\n",
    "    def run_model(self, regr, model_name):\n",
    "        regr.fit(self.X_train, self.y_train)\n",
    "        y_pred = regr.predict(self.X_test)\n",
    "        model_performace(model_name=f\"{model_name}\", y_test=self.y_test, y_pred=y_pred)\n",
    "        if self.LDS == False: \n",
    "            return\n",
    "        regr.fit(self.X_train_LDS, self.y_train_LDS, sample_weight=self.w_train)\n",
    "        y_pred = regr.predict(self.X_test_LDS)\n",
    "        model_performance(model_name=f\"{model_name} (with LDS)\", y_test=self.y_test_LDS, y_pred=y_pred, weights_test=self.w_test)\n",
    "    \n",
    "    def DecisionTree(self):\n",
    "        regr = DecisionTreeRegressor()\n",
    "        self.run_model(regr, \"Decision Tree\")\n",
    "    \n",
    "    def AdaBoost(self):\n",
    "        regr = AdaBoostRegressor(DecisionTreeRegressor(), n_estimators=50)\n",
    "        self.run_model(regr, \"AdaBoost\")\n",
    "\n",
    "    def RandomForest(self):\n",
    "        regr = RandomForestRegressor(n_estimators=100)\n",
    "        self.run_model(regr, \"Random Forest\")\n",
    "\n",
    "    def GB(self):\n",
    "        regr = GradientBoostingRegressor(n_estimators=100)\n",
    "        self.run_model(regr, \"Gradient Boosting\")\n",
    "\n",
    "    def HistGB(self):\n",
    "        regr = HistGradientBoostingRegressor(max_iter=100)\n",
    "        self.run_model(regr, \"Hist Gradient Boosting\")\n",
    "\n",
    "    def XGBoost(self):\n",
    "        regr = XGBRegressor(objective='reg:squarederror', n_estimators=100)\n",
    "        self.run_model(regr, \"XGBoost\")\n",
    "\n",
    "    def LGBM(self):\n",
    "        regr = lgb.LGBMRegressor()\n",
    "        regr.fit(self.X_train, self.y_train, eval_set=[(self.X_test, self.y_test)], eval_metric='mse')\n",
    "        y_pred = regr.predict(self.X_test, num_iteration=regr.best_iteration_)\n",
    "        model_performace(model_name=f\"LightGBM\", y_test=self.y_test, y_pred=y_pred)\n",
    "\n",
    "    def CatBoost(self):\n",
    "        regr = CatBoostRegressor(verbose=0)\n",
    "        regr.fit(self.X_train, self.y_train, eval_set=(self.X_test, self.y_test), use_best_model=True)\n",
    "        y_pred = regr.predict(self.X_test)\n",
    "        model_performace(model_name=f\"CatBoost\", y_test=self.y_test, y_pred=y_pred)\n",
    "\n",
    "    def KNN(self):\n",
    "        regr = KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "        regr.fit(self.X_train_normalized, self.y_train)\n",
    "        y_pred = regr.predict(self.X_test_normalized)\n",
    "        model_performace(model_name=f\"K-Nearest Neighbors\", y_test=self.y_test, y_pred=y_pred)\n",
    "\n",
    "    def MLP(self):\n",
    "        params = { 'hidden_layer_sizes' : [10,10],\n",
    "            'activation' : 'relu', 'solver' : 'adam',\n",
    "            'alpha' : 0.0, 'batch_size' : 10,\n",
    "            'random_state' : 0, 'tol' : 0.0001,\n",
    "            'nesterovs_momentum' : False,\n",
    "            'learning_rate' : 'constant',\n",
    "            'learning_rate_init' : 0.01,\n",
    "            'max_iter' : 1000, 'shuffle' : True,\n",
    "            'n_iter_no_change' : 50, 'verbose' : False }\n",
    "        regr = MLPRegressor(**params)\n",
    "        regr.fit(self.X_train_standardized, self.y_train)\n",
    "        y_pred = regr.predict(self.X_test_standardized)\n",
    "        model_performace(model_name=f\"Multilayer Perceptron\", y_test=self.y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af2c372-a888-4e5f-ade4-a3383104e5e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68301058-33d8-4ee3-8011-c80e84093827",
   "metadata": {},
   "source": [
    "## Models Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b97df8ad-b768-40ed-bef5-b3d43c0ac7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv(\"./data/cleandata.csv\")\n",
    "smogn_02_df = pd.read_csv(\"data/data_smogn_02.csv\")\n",
    "smogn_03_df = pd.read_csv(\"data/data_smogn_03.csv\")\n",
    "smogn_04_df = pd.read_csv(\"data/data_smogn_04.csv\")\n",
    "smogn_05_df = pd.read_csv(\"data/data_smogn_05.csv\")\n",
    "smogn_06_df = pd.read_csv(\"data/data_smogn_06.csv\")\n",
    "smogn_07_df = pd.read_csv(\"data/data_smogn_07.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa505ad-ea50-4d0a-965c-3f076911d2ac",
   "metadata": {},
   "source": [
    "Every dataset contains `weight` column for LDS, so we will run every model twice (if applicable) for each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dea30e-58c6-403d-8cf5-666b60d1d7c2",
   "metadata": {},
   "source": [
    "### Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b67f557-b555-4aa5-addb-f3f0db16798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model on Original Data')\n",
    "Models(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72244950-eae3-421b-9c8f-29e737379173",
   "metadata": {},
   "source": [
    "### SMOGN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104a39b-c56d-4d89-9233-a2e76292574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model on SMOGN (rel_thes = 0.2) Data')\n",
    "Models(smogn_02_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cdeccb-0061-4169-9b11-e62b5908968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model on SMOGN (rel_thes = 0.3) Data')\n",
    "Models(smogn_03_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42761cf6-771b-49d0-bc01-717efb750158",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model on SMOGN (rel_thes = 0.4) Data')\n",
    "Models(smogn_04_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473a0d3-7b60-48f5-a6a0-4284115922f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model on SMOGN (rel_thes = 0.5) Data')\n",
    "Models(smogn_05_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea6053-d678-43d4-94e5-f3a628b20bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model on SMOGN (rel_thes = 0.6) Data')\n",
    "Models(smogn_06_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944faa3-0b23-4ad9-b465-389593cd164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model on SMOGN (rel_thes = 0.7) Data')\n",
    "Models(smogn_07_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ab597-b241-4f0d-a492-18d93d9e6375",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "blah blah blah"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
